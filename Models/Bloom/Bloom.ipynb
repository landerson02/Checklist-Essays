{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af8f26f7-d03f-4cdb-9ba3-eca04b21d519",
   "metadata": {},
   "source": [
    "# 1. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde24445-4ea4-45b4-ba25-273fb10ae7b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc67258-b758-4686-896a-9718cecd0f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Peek at our student essay dataframe\n",
    "# se = pd.read_csv('StudentEssays.xlsx')\n",
    "se = pd.read_excel('StudentEssays.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ff5ec7-f463-4b67-9f10-8b26bc0b6b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# There are 76 rows in total\n",
    "# The essays are stored in the column \"Essay\"\n",
    "# We need to output our classifications into the columns \"PE\", \"KE\", and \"LCE\"\n",
    "se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc07d63-029f-4f89-8ffd-659ed9bd4f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, what is our \"training data\"?\n",
    "# They are in \"Interence Categories and Examples\" sesstion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55dfd67-d451-49f4-8819-457c19a50ba6",
   "metadata": {},
   "source": [
    "## Examples from our document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0fca1-a742-41d6-b882-2b5d4561af86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PE\n",
    "PE_AC = ['Potential energy is energy at rest',\n",
    "'Potential energy is energy that a body has because of its position relative to other bodies.',\n",
    "'Potential energy is energy stored in the car at the top of the initial drop.',\n",
    "'Potential energy is the stored energy of the rollercoaster car when it is not moving.',\n",
    "'Potential energy is energy that has the potential to become another form of energy.']\n",
    "\n",
    "PE_UN = [\"Potential energy is energy in motion.\",\"Potential energy is the energy lost as the car goes down the hill.\",\"Potential energy is the opposite of kinetic energy.\",\"Potential energy is energy that is conserved by not moving.\",\"Potential energy is energy measured in joules.\"]\n",
    "\n",
    "PE_IN = [\"The potential energy at the top of the rollercoaster is 4.9 joules.\",\"Potential energy is measured in joules.\",\"PE = m*h*9.8\",\"There is more potential energy at the top of the hill than the bottom. \",\"The potential energy changes into kinetic energy as the car goes down the hill.\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e87dec-ec6b-4d72-af6c-3e14eb259d61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KE\n",
    "KE_AC = [\"Kinetic energy is energy in motion.\",\"Kinetic energy is energy that the car has because it is moving.\",\"Kinetic energy is the work needed to accelerate the rollercoaster car from rest.\",\"Kinetic energy is determined by the mass of the car and the velocity with which it is moving.\",\"Kinetic energy quantifies the work an object performs due to its motion.\",]\n",
    "\n",
    "KE_UN = [\"Kinetic energy is energy at rest.\",\"Kinetic energy is never lost or gained as the car moves through the rollercoaster.\",\"Kinetic energy is the opposite of potential energy.\",\"Kinetic energy is measured in joules.\",\"Kinetic energy is energy that is spent by moving up and down the hill.\",]\n",
    "\n",
    "KE_IN = [\"The kinetic energy at the bottom of the hill is 4.8 joules.\",\"Kinetic energy is measured in joules.\",\"KE = m*1/2v^2\",\"There is more kinetic energy at the bottom of the hill than at the top.\",\"Kinetic energy transforms into heat through friction.\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f836274-e613-4c35-8ef9-78eb2e7b9c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LCE\n",
    "LCE_AC = [\"LCE says that energy cannot be created or destroyed, only transformed.\",\"LCE states that the total energy of an isolated system remains constant. \",\"LCE states that energy can be converted from one form to another, but never created or destroyed.\",\"LCE says that if there were no friction, the potential energy at the top of the rollercoaster would be the same as the kinetic energy at the bottom of the drop.\",\"LCE is a physical law that states that energy cannot be created or destroyed but only transformed.\",]\n",
    "\n",
    "LCE_UN = [\"LCE says that energy can be created and destroyed.\",\"LCE states that the energy of a closed system will change.\",\"LCE says that in an open system, energy is conserved.\",]\n",
    "\n",
    "LCE_IN = [\"K1 + U1 = K2 + U2\",\"The potential energy transforms into kinetic energy because of the law of conservation of energy.\",\"As the car goes down the hill, some energy is lost to friction as heat.\",\"If there were no friction, the energy would be the same at the start and at the finish.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e888e343-ce41-4817-a9a6-005bfc4e0dbc",
   "metadata": {},
   "source": [
    "## Make this into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3138887-477d-4ba5-b554-31618374357f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now, how do we make this into a training data?\n",
    "# First, install transformers, datasets and evaluate\n",
    "# !pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3374a093-ca66-42a4-afaa-9f4e25904320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans: The dataset is in the datatype \"Datasetdict\" and \"Dataset\"\n",
    "# First, we create our data\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "# For each \"label\", we have 0=unrelated, 1=unacceptable, 2=insufficient, 3=acceptable\n",
    "# Create dataframe from our arrays for each label\n",
    "def create_df(label):\n",
    "    mark = 0\n",
    "    if label=='PE':\n",
    "        mark = 0\n",
    "    elif label=='KE':\n",
    "        mark = 1\n",
    "    else:\n",
    "        mark = 2\n",
    "    \n",
    "    classes = [0 for i in range(9)]\n",
    "    classes[mark*3] = 3\n",
    "    classes[mark*3+1] = 1\n",
    "    classes[mark*3+2] = 2\n",
    "    \n",
    "    text = []\n",
    "    lb = []\n",
    "    texts = [PE_AC,PE_UN,PE_IN,KE_AC,KE_UN,KE_IN,LCE_AC,LCE_UN,LCE_IN]\n",
    "    for i in range(len(texts)):\n",
    "        for j in texts[i]:\n",
    "            text.append(j)\n",
    "            lb.append(classes[i])\n",
    "    \n",
    "    d = {'text': text, 'label': lb}\n",
    "    return pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384084f8-9e7f-4434-a164-26cb083fd64a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_datasetdict(label):\n",
    "    df = create_df(label) # success!\n",
    "    # Now, onto create data for training\n",
    "    d = {'train':Dataset.from_dict({'label':df['label'],'text':df['text']}),}\n",
    "    data = DatasetDict(d)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cfd090-68c7-4db4-87b1-fd1d5573b2e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = create_datasetdict('PE')\n",
    "data['train'][0] # works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8696724-cd50-4314-a22b-fad1777501dd",
   "metadata": {},
   "source": [
    "# 2. Finetuning Model (For PE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb63a2d-866a-4fa6-b6a9-8f57204be1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now, onto finetuning the model\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BloomForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-560m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e817e386-9673-462d-8e30-4aecea84513d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baec9d6d-4945-48d3-aaed-c979ec20da01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_data = data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51fb9ed-3bce-4fb2-806c-2c811657e401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7ff95-f8ee-4776-832e-e533112f6c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573dbcf7-2f2e-4371-ba4d-6c94a01c9dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccacc5a-491d-4d4b-b1a1-ec9f0299c4dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d569d37-2480-4435-bc47-9a12931c1184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id2label = {0:\"unrelated\", 1:\"unacceptable\", 2:\"insufficient\", 3:\"acceptable\"}\n",
    "label2id = {\"unrelated\":0, \"unacceptable\":1, \"insufficient\":2, \"acceptable\":3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074cba5-406e-465b-9d81-fc9fd7fbc74a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BloomForSequenceClassification.from_pretrained(\"bigscience/bloom-560m\",\n",
    "                                                      num_labels=4,\n",
    "                                                      id2label=id2label,\n",
    "                                                      label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c25aaf0-3ac3-47da-88d0-e403cad51f97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad000020-8ee6-48d9-bbb5-02d7e265557e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"finetuned-bloom-560m-PE\",\n",
    "    overwrite_output_dir= True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    load_best_model_at_end=False,\n",
    "    save_total_limit = 2,\n",
    "    #push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f173a13f-8924-40af-b8a5-5826f1840ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c1c54-7f25-4602-874f-f126a78dd49b",
   "metadata": {},
   "source": [
    "# 3. Evaluation\n",
    "\n",
    "Now we will use our model against the student's essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feed598f-6410-48d2-838a-e71390f763ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#nltk.download('popular')\n",
    "\n",
    "# Returns a list of sentences of a given text\n",
    "def split_sent(text):\n",
    "    return sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b824956-b4b5-4ef8-b592-73f804b9e4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-560m\")\n",
    "model = BloomForSequenceClassification.from_pretrained(\"./finetuned-bloom-560m-PE\",\n",
    "                                                      num_labels=4,\n",
    "                                                      id2label=id2label,\n",
    "                                                      label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546456eb-38ac-4f3a-9acf-c2f94cfbc493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9defee1-d16d-4126-b3fd-16b9eecc6b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split_sent(se['Essay'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb8a654-f871-4e88-abcb-5ee9a302fd13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#x = classifier(split_sent(se['Essay'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564293e9-6c2d-4782-8c12-20b3b038d5c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#y = [_['label'] for _ in x]\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81cb555-628d-467b-97c4-662767bb7a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#np.sum([_ == 'insufficient' for _ in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e5ed8d-dd61-4241-b230-3f499f4dd930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#np.sum([_ == 'unrelated' for _ in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49e1a8b-b35c-4f36-adf6-69d1b48054dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#np.sum([_ == 'unacceptable' for _ in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ccecd1-4dbe-412e-aaf3-c366c2b75825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#np.sum([_ == 'acceptable' for _ in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bffe7ef-537c-4d88-8966-f31d18d4c991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df = se[['Essay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a5c50-7911-421a-87a8-fe8c7860db99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a355707-6ef0-455f-8c2e-2ac0cd3a0fde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.zeros(new_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc25e6-2d1b-4be6-a63f-353830b02f67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df['PE_AC'] = pd.Series(np.zeros(new_df.shape[0]))\n",
    "new_df['PE_IN'] = pd.Series(np.zeros(new_df.shape[0]))\n",
    "new_df['PE_UN'] = pd.Series(np.zeros(new_df.shape[0]))\n",
    "new_df['PE_unrelated'] = pd.Series(np.zeros(new_df.shape[0]))\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348bddd1-84ef-4880-8438-7674e63d3f36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we will do this for every essay\n",
    "# What column for each topic do we have?\n",
    "# AC, IN, UN, unrelated\n",
    "for i in range(new_df.shape[0]):\n",
    "    sentences = split_sent(se['Essay'][i])\n",
    "    res = classifier(sentences)\n",
    "    predictions = pd.Series([x['label'] for x in res])\n",
    "    new_df.at[i, 'PE_IN'] = np.sum([_ == 'insufficient' for _ in predictions])\n",
    "    new_df.at[i, 'PE_AC'] = np.sum([_ == 'acceptable' for _ in predictions])\n",
    "    new_df.at[i, 'PE_UN'] = np.sum([_ == 'unacceptable' for _ in predictions])\n",
    "    new_df.at[i, 'PE_unrelated'] = np.sum([_ == 'unrelated' for _ in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552f5fe-20d5-4262-a621-84f007c2ae17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f4d682-8c2e-48b9-96ac-1d5dda946c6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df.to_csv('StudentEssaysPE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4928f11-be8c-4d06-ae14-43838e807073",
   "metadata": {},
   "source": [
    "# 5. Now, do the same for KE and LCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7da36b-56f0-4e02-b2dc-6bd456cebecf",
   "metadata": {},
   "source": [
    "## Kinetic Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c224b8-2f37-4e83-a5d3-1a96016469ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = create_datasetdict('KE')\n",
    "data['train'][0] # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83d844-58b8-4fd6-8dce-4499192c6427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_data = data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f57f0d-41a7-4b5f-8566-131abe308128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BloomForSequenceClassification.from_pretrained(\"bigscience/bloom-560m\",\n",
    "                                                      num_labels=4,\n",
    "                                                      id2label=id2label,\n",
    "                                                      label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2424e04-eb0f-4cd9-a5d6-fc82e8fc9507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"finetuned-bloom-560m-KE\",\n",
    "    overwrite_output_dir= True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    load_best_model_at_end=False,\n",
    "    save_total_limit = 2,\n",
    "    #push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9b320-575f-4e37-ae50-48e426b15da5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68bfda-1d2f-4680-809a-4a9508f4993f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BloomForSequenceClassification.from_pretrained(\"./finetuned-bloom-560m-KE\",\n",
    "                                                      num_labels=4,\n",
    "                                                      id2label=id2label,\n",
    "                                                      label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a495d-bacd-4206-ae85-e2109a680fea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"text-classification\", model=model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48de7d70-07b0-41b8-b5df-7b23d9564808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df['KE_AC'] = pd.Series(np.zeros(new_df.shape[0]))\n",
    "new_df['KE_IN'] = pd.Series(np.zeros(new_df.shape[0]))\n",
    "new_df['KE_UN'] = pd.Series(np.zeros(new_df.shape[0]))\n",
    "new_df['KE_unrelated'] = pd.Series(np.zeros(new_df.shape[0]))\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7bb515-2511-4669-be30-d6458d6b5331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we will do this for every essay\n",
    "# What column for each topic do we have?\n",
    "# AC, IN, UN, unrelated\n",
    "for i in range(new_df.shape[0]):\n",
    "    sentences = split_sent(se['Essay'][i])\n",
    "    res = classifier(sentences)\n",
    "    predictions = pd.Series([x['label'] for x in res])\n",
    "    new_df.at[i, 'KE_IN'] = np.sum([_ == 'insufficient' for _ in predictions])\n",
    "    new_df.at[i, 'KE_AC'] = np.sum([_ == 'acceptable' for _ in predictions])\n",
    "    new_df.at[i, 'KE_UN'] = np.sum([_ == 'unacceptable' for _ in predictions])\n",
    "    new_df.at[i, 'KE_unrelated'] = np.sum([_ == 'unrelated' for _ in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60fff26-6868-4009-9903-7cc3d39f1bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e425eb-32e7-4f4f-9592-a34b8ae5ee9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df.to_csv('StudentEssaysPEKE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c879adc-ebd9-45f4-978a-a523a1499f72",
   "metadata": {},
   "source": [
    "## LCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de7cdf-359b-491f-914a-ba6dbaef5369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = create_datasetdict('LCE')\n",
    "data['train'][-1] # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782570af-2135-43aa-bb95-5b171b003f96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_data = data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2fb449-6c1d-48f5-becf-b93638395f89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BloomForSequenceClassification.from_pretrained(\"bigscience/bloom-560m\",\n",
    "                                                      num_labels=4,\n",
    "                                                      id2label=id2label,\n",
    "                                                      label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5015e1e-be6c-40ed-9105-10284b91987f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"finetuned-bloom-560m-LCE\",\n",
    "    overwrite_output_dir= True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    load_best_model_at_end=False,\n",
    "    save_total_limit = 2,\n",
    "    #push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db960db9-8d67-41f1-9eb0-f1e700fa62da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49feab77-5af0-4222-b817-1b8861f7c5be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BloomForSequenceClassification.from_pretrained(\"./finetuned-bloom-560m-LCE\",\n",
    "                                                      num_labels=4,\n",
    "                                                      id2label=id2label,\n",
    "                                                      label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9570eae1-d328-41be-82fa-c1298ae4122f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"text-classification\", model=model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0386e40f-83a2-4ad0-855d-59b67b4a0295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df['LCE_AC'] = pd.Series(np.zeros(new_df.shape[0]))\n",
    "new_df['LCE_IN'] = pd.Series(np.zeros(new_df.shape[0]))\n",
    "new_df['LCE_UN'] = pd.Series(np.zeros(new_df.shape[0]))\n",
    "new_df['LCE_unrelated'] = pd.Series(np.zeros(new_df.shape[0]))\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69eb052-5035-4625-a273-4beb1f53f05e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we will do this for every essay\n",
    "# What column for each topic do we have?\n",
    "# AC, IN, UN, unrelated\n",
    "for i in range(new_df.shape[0]):\n",
    "    sentences = split_sent(se['Essay'][i])\n",
    "    res = classifier(sentences)\n",
    "    predictions = pd.Series([x['label'] for x in res])\n",
    "    new_df.at[i, 'LCE_IN'] = np.sum([_ == 'insufficient' for _ in predictions])\n",
    "    new_df.at[i, 'LCE_AC'] = np.sum([_ == 'acceptable' for _ in predictions])\n",
    "    new_df.at[i, 'LCE_UN'] = np.sum([_ == 'unacceptable' for _ in predictions])\n",
    "    new_df.at[i, 'LCE_unrelated'] = np.sum([_ == 'unrelated' for _ in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf08e2a-d960-490d-90e2-43ad55f519eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58578042-7f63-402c-aec3-a9e225b8a9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df.to_csv('StudentEssaysPEKELCE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78c315-58a9-4b5b-82f9-e9603afd6abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59de608-5d5b-44a2-9229-b791e79d792c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b7c3a1-8bd0-4640-bc12-21c2db07b870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b89ec-8e73-469c-b1cf-c4fc100e4db4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ok, \"multi-label classifier\" = can be 0 label or all labels\n",
    "# \"Multi-class classifier\" = can be only 1 label\n",
    "# What I \"ideally\" looking for is a \"multi-classification\" inside 3 \"multi-labbel classifiers\"\n",
    "# For now, let's have 3 models of multi-class classification instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425baa79-eca6-4c69-8e39-1628064f3866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
